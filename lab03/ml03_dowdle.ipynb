{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95589812",
   "metadata": {},
   "source": [
    "# Dowdle's Titanic Survival Prediction\n",
    "**Author:** Brittany Dowdle  \n",
    "**Date:** March 26, 2025  \n",
    "**Objective:** Use the data you inspected, explored, and cleaned previously. Use 3 models to predict survival on the Titanic from various input features. Compare model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aa9e4b",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This project uses the Titanic dataset to predict survival based on features such as class, sex, and family size. We will train multiple models, evaluate performance using key metrics, and create visualizations to interpret the results. We use three common classification models in this lab: Decision Tree Classifier (DT), Support Vector Machine (SVM), and Neural Network (NN).\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "In the code cell below, import the necessary Python libraries for this notebook. All imports should be at the top of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for data manipulation and analysis (we might want to do more with it)\n",
    "import pandas as pd\n",
    "\n",
    "# Import pandas for data manipulation and analysis  (we might want to do more with it)\n",
    "import numpy as np\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# Import matplotlib for creating static visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Import seaborn for statistical data visualization (built on matplotlib)\n",
    "import seaborn as sns\n",
    "\n",
    "# Import train_test_split for splitting data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Import LinearRegression for building a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import performance metrics for model evaluation\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## Section 1. Import and Inspect the Data\n",
    "\n",
    "We don't need to inspect the data as we've already done that and are familiar with the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "titanic = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "\n",
    "## Section 2. Data Exploration and Preparation\n",
    "We might need to clean it or do some feature engineering. Learning to figure out what you need is a key skill.\n",
    "\n",
    "### 2.1 Handle Missing Values and Clean Data\n",
    "\n",
    "- Impute missing values for age using the median.\n",
    "- Fill in missing values for embark_town using the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values for age using the median \n",
    "titanic.fillna({'age': titanic['age'].median()}, inplace=True)\n",
    "\n",
    "# Fill missing values for embark_town using the mode\n",
    "titanic['embark_town'] = titanic['embark_town'].fillna(titanic['embark_town'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Feature Engineering\n",
    "\n",
    "- Add family_size - number of family members on board.\n",
    "- Convert categorical \"sex\" to numeric.\n",
    "- Convert categorical \"embarked\" to numeric.\n",
    "- Binary feature - convert \"alone\" to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a869bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create family_size\n",
    "titanic['family_size'] = titanic['sibsp'] + titanic['parch'] + 1\n",
    "\n",
    "# Convert categorical to numeric\n",
    "titanic['sex'] = titanic['sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Convert categorical to numeric\n",
    "titanic['embarked'] = titanic['embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "\n",
    "# Convert binary to numeric\n",
    "titanic['alone'] = titanic['alone'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0acdb8",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3. Feature Selection and Justification\n",
    "\n",
    "### 3.1 Choose features and target\n",
    "For classification you need a categorical target variable (e.g., gender, species). Select two or more input features.\n",
    "\n",
    ">Target: survived\n",
    ">\n",
    ">Input features: age, fare, pclass, sex, family_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e11a66",
   "metadata": {},
   "source": [
    "### 3.2 Define X and y\n",
    "\n",
    "- Assign input features to X\n",
    "- Assign target variable to y (as applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic[['age', 'fare', 'pclass', 'sex', 'family_size']]\n",
    "y = titanic['survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 3:\n",
    "\n",
    "1) Why are these features selected? **Age captures the advantage of younger passengers, fare and class because typically first class costs more and had the highest survival rate, sex and family size for life boat prioritization.**\n",
    "2) Are there any features that are likely to be highly predictive of survival? **Yes, sex first, as women represented a larger share of higher fares. Pclass next, with first-class passengers surviving at much higher rates than those in third class.**\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5676c419",
   "metadata": {},
   "source": [
    "## Section 4. Splitting\n",
    "Split the data into training and test sets using train_test_split first and StratifiedShuffleSplit second. Compare.\n",
    "\n",
    "### 4.1 Basic Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "967ed19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 712\n",
      "Test size: 179\n"
     ]
    }
   ],
   "source": [
    "# Split data into a training set and a test set\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Show set sizes\n",
    "print('Train size:', len(X_train_b))\n",
    "print('Test size:', len(X_test_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Stratified Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 712\n",
      "Test size: 179\n"
     ]
    }
   ],
   "source": [
    "# Define how many splits, % of data for testing, and ensure reproducibility\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=123)\n",
    "\n",
    "# Split data into a training set and a test set\n",
    "for train_indices, test_indices in splitter.split(X, y):\n",
    "    X_train_s = X.iloc[train_indices]\n",
    "    X_test_s = X.iloc[test_indices]\n",
    "    y_train_s = y.iloc[train_indices]\n",
    "    y_test_s = y.iloc[test_indices]\n",
    "\n",
    "# Show set sizes\n",
    "print('Train size:', len(X_train_s))\n",
    "print('Test size:', len(X_test_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351f529b",
   "metadata": {},
   "source": [
    "### 4.3 Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82df3db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Class Distribution:\n",
      " survived\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Basic Split Distribution - Train Set:\n",
      " survived\n",
      "0    0.610955\n",
      "1    0.389045\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Basic Split Distribution - Test Set:\n",
      " survived\n",
      "0    0.636872\n",
      "1    0.363128\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Stratified Split Distribution - Train Set:\n",
      " survived\n",
      "0    0.616573\n",
      "1    0.383427\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Stratified Split Distribution - Test Set:\n",
      " survived\n",
      "0    0.614525\n",
      "1    0.385475\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOriginal Class Distribution:\\n\", y.value_counts(normalize=True))\n",
    "print(\"\\nBasic Split Distribution - Train Set:\\n\", y_train_b.value_counts(normalize=True))\n",
    "print(\"\\nBasic Split Distribution - Test Set:\\n\", y_test_b.value_counts(normalize=True))\n",
    "print(\"\\nStratified Split Distribution - Train Set:\\n\", y_train_s.value_counts(normalize=True))\n",
    "print(\"\\nStratified Split Distribution - Test Set:\\n\", y_test_s.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea6b2c2",
   "metadata": {},
   "source": [
    "### Reflection 4:\n",
    "\n",
    "1) Why might stratification improve model performance? **The dataset was imbalanced across class, and stratification ensures that both the training and test sets maintain the same class distribution as the original dataset. It helps the model learn from a more representative sample of the data, which leads to more reliable performance.**\n",
    "2) How close are the training and test distributions to the original dataset? **Stratified - the distributions for both the training and test sets are very similar to the original proportions. Basic Split - some deviation in the test set, where Class 0 is slightly overrepresented.**\n",
    "3) Which split method produced better class balance? **Stratified Split produced a better class balance because it preserved the original class proportions more accurately in both the training and test sets.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
