{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a023c09c",
   "metadata": {},
   "source": [
    "# Dowdle's Wine Quality Prediction\n",
    "**Author:** Brittany Dowdle\n",
    "**Date:** April 8, 2025\n",
    "**Objective:** Implement an ensemble model, combine multiple models to improve performance. Evaluate the model using performance metrics. Compare results and provide insights.\n",
    "\n",
    "## Introduction\n",
    "This project uses the Wine Quality dataset to predict red wines based on their physicochemical properties. Some features include acidities, sulfur dioxides, and sugars. I will train 2 models: . We are using ensemble models because they usually outperform individual models by reducing overfitting and improving generalization.\n",
    "\n",
    "****\n",
    "\n",
    "## Imports\n",
    "In the code cell below, import the necessary Python libraries for this notebook. All imports should be at the top of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b761f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7c6ef3",
   "metadata": {},
   "source": [
    "****\n",
    "\n",
    "## Section 1. Load and Inspect the Data\n",
    "Load the Wine Quality dataset and confirm it’s structured correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00fc4723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n",
      "None \n",
      "\n",
      "First Few Rows:\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset (download from UCI and save in the same folder)\n",
    "df = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "\n",
    "# Display structure and first few rows\n",
    "print('Info:')\n",
    "print(df.info(), \"\\n\")\n",
    "print('First Few Rows:')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36239338",
   "metadata": {},
   "source": [
    "****\n",
    "\n",
    "## Section 2. Prepare the Data\n",
    "Includes cleaning, feature engineering, encoding, splitting, helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99023a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 duplicate rows!\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate rows\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "\n",
    "# Print results\n",
    "if not duplicate_rows.empty:\n",
    "    print(f\"Found {len(duplicate_rows)} duplicate rows!\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a0f46ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed. New dataset size: (1359, 14)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "print(f\"Duplicates removed. New dataset size: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f5eaf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality_label values:\n",
      "['medium' 'high' 'low']\n"
     ]
    }
   ],
   "source": [
    "# Define helper function (Takes the quality and returns 3 categorical labels (low, medium, high))\n",
    "def quality_to_label(q):\n",
    "    if q <= 4:\n",
    "        return \"low\"\n",
    "    elif q <= 6:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "    \n",
    "# Create the new column the helper function made\n",
    "df[\"quality_label\"] = df[\"quality\"].apply(quality_to_label)\n",
    "\n",
    "# Confirm the column\n",
    "print(\"quality_label values:\")\n",
    "print(df[\"quality_label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f755a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality_numeric values:\n",
      "[1 2 0]\n"
     ]
    }
   ],
   "source": [
    "# Define helper function (Takes the qualiity and simplifies target into 3 categories (0 = low, 1 = medium, 2 = high))\n",
    "def quality_to_number(q):\n",
    "    if q <= 4:\n",
    "        return 0\n",
    "    elif q <= 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# Create the new column the helper function made\n",
    "df[\"quality_numeric\"] = df[\"quality\"].apply(quality_to_number)\n",
    "\n",
    "# Confirm the column\n",
    "print(\"quality_numeric values:\")\n",
    "print(df[\"quality_numeric\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604bcbd0",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "Removing duplicate rows ensures that training and test sets are split correctly later in the project. Simplifying this data from a continuous score into categorized classes helps the data be more suitable for data exploration and visualizations. Having discrete categories enables the model to handle and predict the target variable more effectively.\n",
    "\n",
    "****\n",
    "\n",
    "## Section 3. Feature Selection and Justification\n",
    "The target variable is quality (integer score from 0 to 10, rated by wine tasters). Drop this variable (all 3 columns) from features selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfe9eb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features columns: ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n"
     ]
    }
   ],
   "source": [
    "# Define input features (X) and target (y)\n",
    "X = df.drop(columns=[\"quality\", \"quality_label\", \"quality_numeric\"])  # Features\n",
    "y = df[\"quality_numeric\"]  # Target\n",
    "\n",
    "# Confirm features\n",
    "print(\"Features columns:\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231951cb",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "I dropped the quality columns to prevent the model from learning directly from the target or any of its derivations. Instead, the model will use only the wine’s physicochemical properties as predictors. This setup ensures a clean separation between input features and target labels, and allows us to evalute the models performance compared to actual results later in the project.\n",
    "\n",
    "****\n",
    "\n",
    "## Section 4. Split the Data into Train and Test\n",
    "Split the data into training and test sets using stratify to ensure class balance remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f77bbda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1279\n",
      "Test size: 320\n"
     ]
    }
   ],
   "source": [
    "# Split data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=44, stratify=y)\n",
    "\n",
    "# Show set sizes\n",
    "print('Train size:', len(X_train))\n",
    "print('Test size:', len(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
