{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dowdle's Titanic Survival Prediction\n",
    "**Author:** Brittany Dowdle  \n",
    "**Date:** March, 19, 2025  \n",
    "**Objective:** To inspect, explore, and split data. Compare data splitting methods: train/test split and stratified shuffle split, by evaluating model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This project uses the Titanic dataset to predict survival based on features such as class, sex, and family size. I will clean the data, do some feature engineering, and explore ways to improve performance. This project highlights the importance of balanced data representation.\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "In the code cell below, import the necessary Python libraries for this notebook. All imports should be at the top of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for data manipulation and analysis (we might want to do more with it)\n",
    "import pandas as pd\n",
    "\n",
    "# Import pandas for data manipulation and analysis  (we might want to do more with it)\n",
    "import numpy as np\n",
    "\n",
    "# Import matplotlib for creating static visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import seaborn for statistical data visualization (built on matplotlib)\n",
    "import seaborn as sns\n",
    "\n",
    "# Import train_test_split for splitting data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import LinearRegression for building a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import performance metrics for model evaluation\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## Section 1. Load and Explore the Data\n",
    "\n",
    "### 1.1 Load the dataset and display the first 10 rows\n",
    "Load the California housing dataset directly from `scikit-learn`.\n",
    "- The `fetch_california_housing` function returns a dictionary-like object with the data.\n",
    "- Convert it into a pandas DataFrame.\n",
    "- Display just the first 10 rows using `head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "\n",
    "# Convert the fetched data into a pandas DataFrame\n",
    "df = housing.frame\n",
    "\n",
    "# Might be large. Display just the first 10 rows (you can change this number)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Check for missing values and display summary statistics\n",
    "\n",
    "In the cell below:\n",
    "1. Use `info()` to check data types and missing values.\n",
    "2. Use `describe()` to see summary statistics.\n",
    "3. Use `isnull().sum()` to identify missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use info() to check data types and missing values\n",
    "print(\"Info:\")\n",
    "df.info()\n",
    "\n",
    "# Use describe() to see summary statistics\n",
    "print(\"Describe:\")\n",
    "df.describe()\n",
    "print(df.describe())\n",
    "\n",
    "# Use isnull().sum() to check for missing values in each column\n",
    "print(\"IsNull:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c001a63",
   "metadata": {},
   "source": [
    "Analysis: \n",
    "\n",
    "1) How many data instances (also called data records or data rows) are there? **20,640 data instances**\n",
    "\n",
    "2) How many features (also columns or attributes) are there? **9 features**\n",
    "\n",
    "3) What are the names of the features? (\"Feature\" is used most often in ML projects.) **MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude, MedHouseVal**\n",
    "\n",
    "4) Which features are numeric? **dtypes:float64 so all features are numeric**\n",
    "\n",
    "5) Which features are categorical (non-numeric)? **None since all are numeric**\n",
    "\n",
    "6) Are there any missing values? How should they be handled? Should we delete a sparsely populated column? Delete an incomplete data row? Substitute with a different value? **IsNull output is 0 for all features so there are no missing values, so no action is needed**\n",
    "\n",
    "7) What else do you notice about the dataset? Are there any data issues? **Possible data outliers, unusual values, and highly skewed distributions. Might need to investigate the extreme values to decide if they should be trimmed or transformed and check for feature correlations.**\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. Visualize Feature Distributions\n",
    "### 2.1 Create histograms, boxplots, and scatterplots\n",
    "\n",
    "- Create histograms for all numeric features using `data_frame.hist()` with 30 bins.\n",
    "- Create a boxenplots using `sns.boxenplot()`.\n",
    "- Create scatter plots using `sns.pairplot()`.\n",
    "\n",
    "First, histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms for all numeric features\n",
    "df.hist(bins=30, figsize=(12, 8))\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c4a38b",
   "metadata": {},
   "source": [
    "Second, Boxenplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f0158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxenplot for each column\n",
    "for column in df.columns:\n",
    "    plt.figure( figsize=(6, 4))\n",
    "    sns.boxenplot(x=df[column])\n",
    "    plt.title(f\"Boxenplot for {column}\")\n",
    "    plt.tight_layout()  # Adjust the layout to avoid overlap\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad19958",
   "metadata": {},
   "source": [
    "Third, Scatter Plots:\n",
    "\n",
    "*Pro Tip: Comment out after analysis to speed up the notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c64c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all scatter plots (pairwise plot for numerical columns)\n",
    "sns.pairplot(df)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## Section 3. Feature Selection and Justification\n",
    "### 3.1 Choose two input features for predicting the target\n",
    "\n",
    "- Select `MedInc` and `AveRooms` as predictors.\n",
    "- Select `MedHouseVal` as the target variable.\n",
    "\n",
    "In the following, \n",
    "X is capitalized because it represents a matrix (consistent with mathematical notation).\n",
    "y is lowercase because it represents a vector (consistent with mathematical notation).\n",
    "\n",
    "First:\n",
    "- Create a list of contributing features and the target variable\n",
    "- Define the target feature string (the variable we want to predict)\n",
    "- Define the input DataFrame\n",
    "- Define the output DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input features (predictors)\n",
    "features = ['MedInc', 'AveRooms']\n",
    "\n",
    "# Define the target variable (target variable)\n",
    "target = 'MedHouseVal'\n",
    "\n",
    "# Define the input DataFrame (X) - Matrix of features\n",
    "df_X = df[features]\n",
    "\n",
    "# Define the output DataFrame (y) - Vector of target variable\n",
    "df_y = df[target]\n",
    "\n",
    "\n",
    "# Display first few rows\n",
    "print(\"Features:\")\n",
    "print(df_X.head())\n",
    "print(\"Targets:\")\n",
    "print(df_y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## Section 4. Train a Linear Regression Model\n",
    "### 4.1 Split the data\n",
    "Split the dataset into training and test sets (80% train / 20% test).\n",
    "\n",
    "Call train_test_split() by passing in: \n",
    "\n",
    "- df_X – Feature matrix (input data) as a pandas DataFrame\n",
    "- df_y – Target values as a pandas Series\n",
    "- test_size – Fraction of data to use for testing (e.g., 0.1 = 10%)\n",
    "- random_state – Seed value for reproducible splits\n",
    "\n",
    "We'll get back four return values:\n",
    "\n",
    "- X_train – Training set features (DataFrame)\n",
    "- X_test – Test set features (DataFrame)\n",
    "- y_train – Training set target values (Series)\n",
    "- y_test – Test set target values (Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (80% train / 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_X, df_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Display confirmation of the split\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train the model\n",
    "Create and fit a `LinearRegression` model.\n",
    "\n",
    "LinearRegression – A class from sklearn.linear_model that creates a linear regression model.\n",
    "\n",
    "model – An instance of the LinearRegression model. This object will store the learned coefficients and intercept after training.\n",
    "\n",
    "fit() – Trains the model by finding the best-fit line for the training data using the Ordinary Least Squares (OLS) method.\n",
    "\n",
    "X_train – The input features used to train the model.\n",
    "\n",
    "y_train – The target values used to train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train (fit) the model using training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Display the coefficients and intercept\n",
    "print(\"Model coefficients:\", model.coef_)\n",
    "print(\"Model intercept:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5676c419",
   "metadata": {},
   "source": [
    "Make predictions for the test set.\n",
    "\n",
    "The model.predict() method applies this equation to the X test data to compute predicted values.\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred contains all the predicted values for all the rows in X_test based on the linear regression model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ed19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Create a DataFrame to show Actual and Predicted values\n",
    "compare_df = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': y_pred    \n",
    "})\n",
    "\n",
    "# Display the first few rows of the comparison\n",
    "print(\"Compare the values:\")\n",
    "print(compare_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Report R^2, MAE, RMSE\n",
    "Evaluate the model using R^2, MAE, and RMSE.\n",
    "\n",
    "First:\n",
    "\n",
    "- Coefficient of Determination (R^2) - This tells you how well the model explains the variation in the target variable. A value close to 1 means the model fits the data well; a value close to 0 means the model doesn’t explain the variation well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate R² (Coefficient of Determination)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Display the R² value\n",
    "print(f\"R² Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351f529b",
   "metadata": {},
   "source": [
    "Second:\n",
    "\n",
    "- Mean Absolute Error (MAE) - This is the average of the absolute differences between the predicted values and the actual values. A smaller value means the model’s predictions are closer to the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df3db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Display the MAE value\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cf1fd0",
   "metadata": {},
   "source": [
    "Third:\n",
    "\n",
    "- Root Mean Squared Error (RMSE) - This is the square root of the average of the squared differences between the predicted values and the actual values. It gives a sense of how far the predictions are from the actual values, with larger errors having more impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Display the RMSE value\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e58d40a",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea6b2c2",
   "metadata": {},
   "source": [
    "Analysis: How well did the model perform? Any surprises in the results?\n",
    "\n",
    "* The R² score explains about 46% of the variance. This means that more than half remains unexplained. Some ways to improve would be including additional relative features or explore more complex modeling approaches.\n",
    "* The MAE and RSME are relatively close. The RSME is sensitive to larger errors which would explain why it is slightly higher. For example, one of the rows shows an actual value of 5.00001 being predicted as 1.95573 - which is a considerable underestimation.\n",
    "* The linear regression might not be fully capturing the underlying patterns. The R², MAE, and RSME hint that the underlying relationships might be non-linear!\n",
    "* Switching to a non-linear model or investigating data points and applying data scaling or outlier treatment might improve predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
